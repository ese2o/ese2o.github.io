---
layout: page
title: Large Language Model
description: >
  llm만 하는건 아니고 그냥 AI 논문 리뷰. 레이아웃 조만간 바꿀 예정 ..
sitemap: false
hide_last_modified: true
permalink: /llm/
---

[LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders]{:.heading.flip-title} \
[GPT-1: Improving Language Understanding by Generative Pre-Training]{:.heading.flip-title} \
[GPT-2: Language Models are Unsupervised Multitask Learners]{:.heading.flip-title} \
[GPT-3: Language Models are Few-Shot Learners]{:.heading.flip-title} \
[FLAN: Finetuned Language Models Are Zero-shot Learners]{:.heading.flip-title} \
[RAG: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks]{:.heading.flip-title} \
[LLaVA: Visual Instruction Tuning]{:.heading.flip-title} \
[T-RAG: LESSONS FROM THE LLM TRENCHES]{:.heading.flip-title} \
[Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity]{:.heading.flip-title} \
[REALM: Retrieval-Augmented Language Model Pre-Training]{:.heading.flip-title} \
[LLM Agent; Can Large Language Model Agents Simulate Human Trust Behavior?]{:.heading.flip-title} \
[Eval; CRAG: Comprehensive RAG Benchmark]{:.heading.flip-title} \
[Eval; G-EVAL: NLG Evaluation using GPT-4 with Better Human Alignment]{:.heading.flip-title} \
[Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes]{:.heading.flip-title} \
[AI Agent; The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery]{:.heading.flip-title} \
[MoE; Mixtral of Experts]{:.heading.flip-title}


[LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders]: /llm/2024-05-16-llm1
[GPT-1: Improving Language Understanding by Generative Pre-Training]: /llm/2024-05-16-llm2
[GPT-2: Language Models are Unsupervised Multitask Learners]: /llm/2025-12-24-llm3
[GPT-3: Language Models are Few-Shot Learners]: /llm/2025-12-27-llm4
[FLAN: Finetuned Language Models Are Zero-shot Learners]: /llm/2025-12-27-llm5
[RAG: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks]: /llm/2025-01-05-llm6
[LLaVA: Visual Instruction Tuning]: /llm/2025-01-17-llm7
[T-RAG: LESSONS FROM THE LLM TRENCHES]: /llm/2025-01-24-llm8
[Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity]: /llm/2025-01-30-llm9
[REALM: Retrieval-Augmented Language Model Pre-Training]: /llm/2025-02-07-llm10
[LLM Agent; Can Large Language Model Agents Simulate Human Trust Behavior?]: /llm/2025-02-21-llm11
[Eval; CRAG: Comprehensive RAG Benchmark]: /llm/2025-02-25-llm12
[Eval; G-EVAL: NLG Evaluation using GPT-4 with Better Human Alignment]: /llm/2025-02-28-llm13
[Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes]: /llm/2025-03-07-llm14
[AI Agent; The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery]: /llm/2025-03-21-llm15
[MoE; Mixtral of Experts]: /llm/2025-03-21-llm16